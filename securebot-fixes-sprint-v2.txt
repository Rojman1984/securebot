Fix priority issues in ~/securebot. Apply all fixes, test each one,
then run a final smoke test before reporting done.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONTEXT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SecureBot is a self-hosted AI assistant. Key services:
- Gateway: http://localhost:8080
- Vault:   http://localhost:8200
- RAG:     http://localhost:8400
- Ollama:  http://localhost:11434
- CLI:     ~/securebot/securebot-cli.py (curses TUI)

Primary model is changing from llama3:8b to llama3.2:3b.
Read .env to understand current RESPONSE_MODEL and CLASSIFIER_MODEL.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 1 â€” MODEL SWAP: llama3:8b â†’ llama3.2:3b
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

In ~/securebot/.env:
  Change RESPONSE_MODEL=llama3:8b to RESPONSE_MODEL=llama3.2:3b

In ~/securebot/securebot-cli.py:
  Find the header bar that shows model name (search for "llama3" or
  RESPONSE_MODEL display in _draw_header). Update to read from
  RESPONSE_MODEL env var dynamically instead of hardcoding.
  It should show whatever model is in .env, not a hardcoded string.

Verify: grep RESPONSE_MODEL ~/securebot/.env

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 2 â€” OLLAMA STARTUP TIMING / FIRST REQUEST TIMEOUT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: First request after CLI startup always times out because
Ollama hasn't loaded the model into VRAM yet. This happens on both
machines even with OLLAMA_KEEP_ALIVE=-1 if the model was swapped.

FIX in securebot-cli.py _startup() method:

After rag_warmup() completes, add an Ollama warmup call:

def _ollama_warmup(self):
    """Send a tiny request to force model load before first user message."""
    try:
        import urllib.request, json
        payload = json.dumps({
            "model": os.getenv("RESPONSE_MODEL", "llama3.2:3b"),
            "prompt": "hi",
            "stream": False,
            "options": {"num_predict": 1}
        }).encode()
        req = urllib.request.Request(
            "http://localhost:11434/api/generate",
            data=payload,
            headers={"Content-Type": "application/json"},
            method="POST"
        )
        urllib.request.urlopen(req, timeout=60)
        self.chat.add("Model warmed up.", C_DIM)
    except Exception as e:
        self.chat.add(f"Warmup warning: {e}", C_YELLOW)
    finally:
        self._redraw_needed.set()

Call this in _startup() after RAG warmup, before marking Ready.
Show "Warming up model..." status message while it runs.
This adds ~5-15s to startup but eliminates first-request timeout.

Also increase gateway timeout for POST /message in the CLI:
Find http_post call to GATEWAY_URL/message, increase timeout from
60 to 120 seconds to handle cold starts on slower hardware (P1).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 3 â€” RAG STATUS RACE CONDITION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: CLI shows "RAG not reachable" on startup even though RAG
is healthy. The startup thread checks RAG before services finish
initializing, then never updates the status.

FIX in securebot-cli.py _startup():

Replace single RAG check with retry loop:

def rag_warmup_with_retry(max_attempts=5, delay=3):
    for attempt in range(max_attempts):
        try:
            result = http_get(
                f"{RAG_URL}/context?query=hello&max_tokens=10",
                signed=True,
                timeout=5
            )
            if result is not None:
                return True
        except Exception:
            pass
        if attempt < max_attempts - 1:
            self.chat.add(
                f"RAG not ready, retrying ({attempt+1}/{max_attempts})...",
                C_YELLOW
            )
            self._redraw_needed.set()
            time.sleep(delay)
    return False

Use this instead of the single rag_warmup() call.
Show "RAG ready." in green on success, yellow warning on failure
(do NOT show red error â€” RAG may still come up, and /status will
show true state).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 4 â€” EMPTY SEARCH RESPONSE (raw JSON dict in chat)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: "What is today's date?" returns raw Python dict:
{'status': 'success', 'response': '', 'metadata': {...}}

This means gateway returned method=web_search_needed but empty
response string. The CLI displays raw dict because response is empty.

FIX A â€” in securebot-cli.py _send_message() _worker():

After receiving resp from gateway, add guard:
  bot_text = (resp.get("response") or
              resp.get("text") or
              resp.get("message") or "")

  if not bot_text or bot_text.strip() == "":
      # Gateway returned empty - show metadata for debugging
      method = resp.get("metadata", {}).get("method", "unknown")
      self.chat.add(
          f"[No response â€” method: {method}. Try rephrasing.]",
          C_YELLOW
      )
  elif bot_text.startswith("{") and "status" in bot_text:
      # Raw dict leaked through - extract or show error
      self.chat.add("[Gateway error â€” raw response received]", C_RED)
  else:
      self.chat.add(f"ğŸ¤– Bot: {bot_text}", C_BOT)

FIX B â€” in gateway/gateway_service.py or orchestrator.py:

Find where method is set to "web_search_needed". This should EXECUTE
the search, not just flag it. Trace the code path:
1. Find where response["metadata"]["method"] = "web_search_needed"
2. Check if search is actually called after this point
3. If not, add the search execution call before returning response
4. Ensure empty response never reaches the client â€” if search fails,
   fall back to Ollama with a note: "I couldn't search for that,
   but based on my knowledge..."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 5 â€” CHAT PANEL WORD-WRAP / FRAGMENT RENDERING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: Bot responses render as disconnected fragments on separate
lines instead of flowing paragraphs. Example:
  "I will create a skill for you. Here is an example..."
  "time from the local host operating system..."
  "datetime?" or any variation..."

This is because the model returns newlines in its response and the
CLI splits on \n before word-wrapping to panel width.

FIX in securebot-cli.py _draw_chat() or wherever chat lines are
word-wrapped for display:

When rendering a bot message:
1. First JOIN lines that are clearly continuations (don't start with
   bullet â€¢, -, *, number+dot, or code fence ```)
2. THEN word-wrap the joined text to panel width
3. Preserve intentional structure: blank lines, bullets, code blocks

Algorithm:
  def _wrap_message(text, width):
      # Split into paragraphs on blank lines
      paragraphs = re.split(r'\n\s*\n', text)
      result = []
      for para in paragraphs:
          lines = para.split('\n')
          # Check if structured (bullets, code, headers)
          if any(l.strip().startswith(('- ', '* ', 'â€¢ ', '```', '#'))
                 for l in lines):
              # Preserve structure, just wrap long lines
              for line in lines:
                  result.extend(textwrap.wrap(line, width) or [''])
          else:
              # Join and rewrap as prose
              joined = ' '.join(l.strip() for l in lines if l.strip())
              result.extend(textwrap.wrap(joined, width) or [''])
          result.append('')  # blank line between paragraphs
      return result

Apply this to bot responses before adding to chat buffer.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 6 â€” TASKS PANEL SHOWING RAG GARBAGE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: The tasks section in the chat or system prompt is showing
random ChromaDB chunks (training material) instead of actual tasks.
This means the system prompt builder is calling RAG for tasks
instead of reading tasks.json directly.

FIX in securebot-cli.py SystemPromptBuilder.build():

Find where tasks are injected into the system prompt. It should read
tasks.json DIRECTLY, never from RAG:

def _load_tasks(self):
    tasks_path = os.path.join(MEMORY_DIR, "tasks.json")
    try:
        with open(tasks_path) as f:
            data = json.load(f)
        active = data.get("active_task")
        todo = data.get("todo", [])
        completed = data.get("completed", [])

        lines = []
        if active:
            lines.append(f"Active: {active.get('title','?')} "
                        f"({active.get('status','?')})")
        if todo:
            lines.append("Pending:")
            for t in todo[:5]:  # max 5 tasks in prompt
                pri = t.get('priority','medium')
                lines.append(f"  [{pri}] {t.get('title','?')}")
        return '\n'.join(lines) if lines else "No active tasks."
    except Exception as e:
        return f"Tasks unavailable: {e}"

Ensure this is called directly in build(), NOT via RAG context.
RAG is for memory/conversation history only.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 7 â€” httpx TIMEOUTS IN GATEWAY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: orchestrator.py has httpx calls with no explicit timeout,
causing gateway to hang indefinitely on slow responses.

FIX in gateway/orchestrator.py:

Find all httpx.get() and httpx.post() calls.
Add explicit timeouts:
  - Ollama inference: timeout=120.0
  - RAG service calls: timeout=10.0
  - Vault calls: timeout=10.0
  - Any other service: timeout=10.0

Pattern:
  # Before
  resp = await client.post(url, json=payload)
  # After
  resp = await client.post(url, json=payload, timeout=120.0)

Or use httpx.Timeout:
  timeout = httpx.Timeout(10.0, read=120.0)  # 10s connect, 120s read

Apply to ALL httpx calls in orchestrator.py and gateway_service.py.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TESTING REQUIREMENTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After all fixes, run in order:

1. Syntax check:
   python3 -m py_compile ~/securebot/securebot-cli.py && echo "CLI OK"

2. Verify model swap:
   grep RESPONSE_MODEL ~/securebot/.env

3. Verify timeouts added to gateway:
   grep -c "timeout=" ~/securebot/gateway/orchestrator.py
   # Should be >= 5

4. Verify tasks use direct file read:
   grep -n "tasks.json" ~/securebot/securebot-cli.py
   # Should show direct open() call, not RAG URL

5. Rebuild containers:
   cd ~/securebot && docker compose up -d --build

6. Wait 15 seconds then test:
   curl -s http://localhost:8080/health | python3 -m json.tool
   curl -s http://localhost:8200/health | python3 -m json.tool
   curl -s http://localhost:8400/health | python3 -m json.tool

7. Test search works:
   curl -s -X POST http://localhost:8080/message \
     -H "Content-Type: application/json" \
     -H "X-API-Key: $(grep GATEWAY_API_KEY ~/securebot/.env | cut -d= -f2)" \
     -d '{"channel":"api","user_id":"roland","text":"What is todays date and time?"}' \
     | python3 -c "import sys,json; r=json.load(sys.stdin); print(r.get('response','EMPTY'))"
   # Must NOT return empty string or raw dict

8. Launch CLI and verify:
   - No timeout on first message
   - RAG shows ready (with retry if needed)
   - /status shows all 5 services green
   - Tasks show actual task titles, not random text

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIX 8 â€” CURSOR NOT VISIBLE IN INPUT LINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: The cursor is invisible at the input prompt. User cannot
see where they are typing in the [tone:x|v:x] > input line.

FIX in securebot-cli.py:

1. In setup(), ensure cursor is explicitly enabled:
   curses.curs_set(2)  # 2 = highly visible block cursor
                       # (1 = underline, 0 = invisible)
   If curs_set(2) raises curses.error (some terminals don't support
   it), fall back to curs_set(1), then curs_set(0) as last resort.

   Use this safe wrapper:
   for visibility in (2, 1):
       try:
           curses.curs_set(visibility)
           break
       except curses.error:
           pass

2. In _place_cursor() or _draw_input(), after drawing the input line,
   explicitly move cursor to correct position:

   def _place_cursor(self, lyt):
       try:
           input_row = lyt["input"]  # or however input row is stored
           # Calculate cursor x position:
           # prompt prefix width + cursor_pos
           prompt = f"[tone:{self.tone}|v:{self.verbosity}] > "
           cursor_x = len(prompt) + self.cursor_pos
           # Clamp to terminal width
           h, w = self.stdscr.getmaxyx()
           cursor_x = min(cursor_x, w - 1)
           self.stdscr.move(input_row, cursor_x)
       except curses.error:
           pass

3. Ensure _place_cursor() is called as the LAST operation in
   redraw(), after all other drawing is done. The cursor must be
   positioned after stdscr.refresh() is called, or it will be
   repositioned by the refresh.

   Correct order in redraw():
   self.stdscr.erase()
   # ... all draw calls ...
   self.stdscr.refresh()
   self._place_cursor(lyt)  # AFTER refresh

4. Also ensure curses.echo() is NOT called anywhere â€” it causes
   double-printing of typed characters and cursor artifacts.
   Verify: grep -n "curses.echo" securebot-cli.py  # must be empty

Only report DONE when all 8 checks pass.
